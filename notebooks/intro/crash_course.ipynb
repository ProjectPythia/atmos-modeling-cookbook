{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start here! If you can directly link to an image relevant to your notebook, such as [canonical logos](https://github.com/numpy/numpy/blob/main/doc/source/_static/numpylogo.svg), do so here at the top of your notebook. You can do this with Markdown syntax,\n",
    "\n",
    "> `![<image title>](http://link.com/to/image.png \"image alt text\")`\n",
    "\n",
    "or edit this cell to see raw HTML `img` demonstration. This is preferred if you need to shrink your embedded image. **Either way be sure to include `alt` text for any embedded images to make your content more accessible.**\n",
    "\n",
    "<img src=\"images/ProjectPythia_Logo_Final-01-Blue.svg\" width=250 alt=\"Project Pythia Logo\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crash Course Towards Your First Model\n",
    "\n",
    "Next, title your notebook appropriately with a top-level Markdown header, `#`. Do not use this level header anywhere else in the notebook. Our book build process will use this title in the navbar, table of contents, etc. Keep it short, keep it descriptive. Follow this with a `---` cell to visually distinguish the transition to the prerequisites section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "If you have an introductory paragraph, lead with it here! Keep it short and tied to your material, then be sure to continue into the required list of topics below,\n",
    "\n",
    "1. This is a numbered list of the specific topics\n",
    "1. These should map approximately to your main sections of content\n",
    "1. Or each second-level, `##`, header in your notebook\n",
    "1. Keep the size and scope of your notebook in check\n",
    "1. And be sure to let the reader know up front the important concepts they'll be leaving with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "This section was inspired by [this template](https://github.com/alan-turing-institute/the-turing-way/blob/master/book/templates/chapter-template/chapter-landing-page.md) of the wonderful [The Turing Way](https://the-turing-way.netlify.app) Jupyter Book.\n",
    "\n",
    "Following your overview, tell your reader what concepts, packages, or other background information they'll **need** before learning your material. Tie this explicitly with links to other pages here in Foundations or to relevant external resources. Remove this body text, then populate the Markdown table, denoted in this cell with `|` vertical brackets, below, and fill out the information following. In this table, lay out prerequisite concepts by explicitly linking to other Foundations material or external resources, or describe generally helpful concepts.\n",
    "\n",
    "Label the importance of each concept explicitly as **helpful/necessary**.\n",
    "\n",
    "| Concepts | Importance | Notes |\n",
    "| --- | --- | --- |\n",
    "| [Intro to Cartopy](https://foundations.projectpythia.org/core/cartopy/cartopy.html) | Necessary | |\n",
    "| [Understanding of NetCDF](https://foundations.projectpythia.org/core/data-formats/netcdf-cf.html) | Helpful | Familiarity with metadata structure |\n",
    "| Project management | Helpful | |\n",
    "\n",
    "- **Time to learn**: estimate in minutes. For a rough idea, use 5 mins per subsection, 10 if longer; add these up for a total. Safer to round up and overestimate.\n",
    "- **System requirements**:\n",
    "    - Populate with any system, version, or non-Python software requirements if necessary\n",
    "    - Otherwise use the concepts table above and the Imports section below to describe required packages as necessary\n",
    "    - If no extra requirements, remove the **System requirements** point altogether"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Here we'll be using a basic set of Python libraries, along with Numba for fast numerical routines. A helpful constants file is also imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numba\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...TODO..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some subsection code\n",
    "new = \"helpful information\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Equations\n",
    "\n",
    "...TODO..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting Equations\n",
    "\n",
    "...TODO..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions and Simplification\n",
    "\n",
    "...TODO..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Prognostic Equations\n",
    "\n",
    "...TODO..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration\n",
    "\n",
    "...TODO..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Type\n",
    "\n",
    "...TODO..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial/Boundary Conditions\n",
    "\n",
    "...TODO..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discritization\n",
    "\n",
    "...TODO..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit()\n",
    "def u_tendency_u_advection_term(u, dx):\n",
    "    term = np.zeros_like(u)\n",
    "    for k in range(1, u.shape[0] - 1):\n",
    "        for i in range(1, u.shape[1] - 1):\n",
    "            term[k, i] = u[k, i] * (u[k, i + 1] - u[k, i - 1]) / (2 * dx)\n",
    "    return term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit()\n",
    "def u_tendency_w_advection_term(u, w, dz):\n",
    "    term = np.zeros_like(u)\n",
    "    for k in range(1, u.shape[0] - 1):\n",
    "        for i in range(1, u.shape[1] - 1):\n",
    "            term[k, i] = 0.25 * (\n",
    "                w[k + 1, i] + w[k + 1, i - 1] + w[k, i] + w[k, i - 1] \n",
    "            ) * (u[k + 1, i] - u[k - 1, i]) / (2 * dz)\n",
    "    return term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit()\n",
    "def u_tendency_pgf_term(u, pi, theta_base, dx):\n",
    "    term = np.zeros_like(u)\n",
    "    for k in range(1, u.shape[0] - 1):\n",
    "        for i in range(1, u.shape[1] - 1):\n",
    "            term[k, i] = c_p * theta_base[k] * (pi[k, i] - pi[k, i - 1]) / dx\n",
    "    return term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit()\n",
    "def u_tendency(u, w, pi, theta_base, dx, dz):\n",
    "    return (\n",
    "        u_tendency_u_advection_term(u, dx)\n",
    "        + u_tendency_w_advection_term(u, w, dz)\n",
    "        + u_tendency_pgf_term(u, pi, theta_base, dx)\n",
    "    ) * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit()\n",
    "def theta_p_tendency_u_advection_term(u, theta_p, dx):\n",
    "    term = np.zeros_like(theta_p)\n",
    "    for k in range(1, theta_p.shape[0] - 1):\n",
    "        for i in range(1, theta_p.shape[1] - 1):\n",
    "            term[k, i] = (\n",
    "                (u[k, i + 1] + u[k, i]) / 2\n",
    "                * (theta_p[k, i + 1] - theta_p[k, i - 1]) / (2 * dx)\n",
    "            )\n",
    "    return term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit()\n",
    "def theta_p_tendency_w_advection_of_perturbation_term(w, theta_p, dz):\n",
    "    term = np.zeros_like(theta_p)\n",
    "    for k in range(1, theta_p.shape[0] - 1):\n",
    "        for i in range(1, theta_p.shape[1] - 1):\n",
    "            term[k, i] = (\n",
    "                (w[k + 1, i] + w[k, i]) / 2\n",
    "                * (theta_p[k + 1, i] - theta_p[k - 1, i]) / (2 * dz)\n",
    "            )\n",
    "    return term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit()\n",
    "def theta_p_tendency_w_advection_of_base_term(w, theta_p, theta_base, dz):\n",
    "    term = np.zeros_like(theta_p)\n",
    "    for k in range(1, theta_p.shape[0] - 1):\n",
    "        for i in range(1, theta_p.shape[1] - 1):\n",
    "            term[k, i] = (\n",
    "                (w[k + 1, i] + w[k, i]) / 2\n",
    "                * (theta_base[k + 1] - theta_base[k - 1]) / (2 * dz)\n",
    "            )\n",
    "    return term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit()\n",
    "def theta_p_tendency(u, w, theta_p, theta_base, dx, dz):\n",
    "    return (\n",
    "        theta_p_tendency_u_advection_term(u, theta_p, dx)\n",
    "        + theta_p_tendency_w_advection_of_perturbation_term(w, theta_p, dz)\n",
    "        + theta_p_tendency_w_advection_of_base_term(w, theta_p, theta_base, dz)\n",
    "    ) * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.58.1'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numba.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit()\n",
    "def pi_tendency(u, w, pi, theta_base, rho_base, c_s_sqr, dx, dz):\n",
    "    term = np.zeros_like(pi)\n",
    "    for k in range(1, pi.shape[0] - 1):\n",
    "        for i in range(1, pi.shape[1] - 1):\n",
    "            term[k, i] = (\n",
    "                -1 * (c_s_sqr / (c_p * rho_base[k] * theta_base[k]**2))\n",
    "                * (\n",
    "                    (rho_base[k] * theta_base[k] * (u[k, i + 1] - u[k, i]) / dx)\n",
    "                    + (\n",
    "                        (w[k + 1, i] + w[k, i]) / 2\n",
    "                        * (rho_base[k + 1] * theta_base[k + 1] - rho_base[k - 1] * theta_base[k - 1]) / (2 * dz)\n",
    "                    )\n",
    "                    + (rho_base[k] * theta_base[k] * (w[k + 1, i] - w[k, i]) / dz)\n",
    "                )\n",
    "            )\n",
    "    return term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "# TODO: this should probably go into a separate file!\n",
    "\n",
    "@numba.njit()\n",
    "def nondimensional_pressure_hydrostatic(theta, z, pressure_surface):\n",
    "    pi = np.zeros_like(theta)\n",
    "    # Start at (w level) surface as given\n",
    "    pi_sfc = (pressure_surface / p0)**(R_d / c_p)\n",
    "    # Go down, half level, for u level, using above-surface theta\n",
    "    pi[0] = pi_sfc + gravity * (z[1] - z[0]) / (2 * c_p * theta[1])\n",
    "    # Now, integrate upward over full u levels\n",
    "    for i in range(1, pi.shape[0]):\n",
    "        theta_at_level = 0.5 * (theta[i] + theta[i - 1])\n",
    "        pi[i] = pi[i - 1] - gravity * (z[i] - z[i - 1]) / (c_p * theta_at_level)\n",
    "    return pi\n",
    "\n",
    "@numba.njit()\n",
    "def density_from_ideal_gas_law(theta, pi):\n",
    "    return p0 * pi ** (c_v / R_d) / (R_d * theta)\n",
    "\n",
    "@numba.njit()\n",
    "def create_thermal_bubble(amplitude, x, z, x_radius, z_radius, x_center, z_center, theta_base):\n",
    "    # Coordinates in 2d\n",
    "    xx = np.broadcast_to(x[None, :], (z.shape[0], x.shape[0]))\n",
    "    zz = np.broadcast_to(z[:, None], (z.shape[0], x.shape[0]))\n",
    "    rad = np.sqrt(((zz - z_center) / z_radius)**2 + ((xx - x_center) / x_radius)**2)\n",
    "    # Create thermal bubble\n",
    "    theta_p = np.zeros_like(xx)\n",
    "    for k in range(rad.shape[0]):\n",
    "        for i in range(rad.shape[1]):\n",
    "            if rad[k, i] <= 1.0:\n",
    "                theta_p[k, i] = 0.5 * amplitude * (np.cos(np.pi * rad[k, i]) + 1.0)\n",
    "    # Create balanced pi, integrating downward from assumed zero at topmost level\n",
    "    pi = np.zeros_like(th)\n",
    "    for k in range(rad.shape[0] - 2, -1, -1):\n",
    "        for i in range(rad.shape[1]):\n",
    "            integrand_trapz = 0.5 * (\n",
    "                theta_p[k + 1, i] / theta_base[k + 1]**2\n",
    "                + theta_p[k, i] / theta_base[k]**2\n",
    "            )\n",
    "            pi[k, i] = pi[k + 1, i] - g * (z[k + 1] - z[k]) / c_p * integrand_trapz\n",
    "    # Return results\n",
    "    return theta_p, pi\n",
    "\n",
    "@numba.njit()\n",
    "def apply_periodic_lateral_zerograd_vertical(a):\n",
    "    # Bottom and top (no gradient)\n",
    "    for i in range(0, a.shape[1]):\n",
    "        a[0, i] = a[1, i]\n",
    "        a[a.shape[0] - 1, i] = a[a.shape[0] - 2, i]\n",
    "    # Left and right (mirrored)\n",
    "    for k in range(1, a.shape[0] - 1):\n",
    "        a[k, 0] = a[k, a.shape[1] - 2]\n",
    "        a[k, a.shape[1] - 1] = a[k, 1]\n",
    "    return a\n",
    "\n",
    "@numba.njit()\n",
    "def apply_periodic_lateral_zerow_vertical(a):\n",
    "    # Bottom and top (fixed zero)\n",
    "    for i in range(0, a.shape[1]):\n",
    "        a[0, i] = a[1, i] = 0\n",
    "        a[a.shape[0] - 1, i] = a[a.shape[0] - 2, i] = 0\n",
    "    # Left and right (mirrored)\n",
    "    for k in range(1, a.shape[0] - 1):\n",
    "        a[k, 0] = a[k, a.shape[1] - 2]\n",
    "        a[k, a.shape[1] - 1] = a[k, 1]\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_attrs = {\n",
    "    'u': {\n",
    "        'units': 'm/s'\n",
    "    },\n",
    "    'w': {\n",
    "        'units': 'm/s'\n",
    "    },\n",
    "    'theta_p': {\n",
    "        'units': 'K'\n",
    "    },\n",
    "    'pi': {\n",
    "        'units': 'dimensionless'\n",
    "    },\n",
    "    'x': {\n",
    "        'units': 'm'\n",
    "    },\n",
    "    'x_stag': {\n",
    "        'units': 'm'\n",
    "    },\n",
    "    'z': {\n",
    "        'units': 'm'\n",
    "    },\n",
    "    'z_stag': {\n",
    "        'units': 'm'\n",
    "    },\n",
    "    't': {\n",
    "        'units': 's'\n",
    "    }\n",
    "}\n",
    "\n",
    "class ModelDriver:\n",
    "\n",
    "    coords = {}\n",
    "    prognostic_arrays = {}\n",
    "    base_state_arrays = {}\n",
    "    diagnostic_arrays = {}\n",
    "    params = {}\n",
    "\n",
    "    def __init__(self, nx, nz, dx, dz, dt, **kwargs):\n",
    "        # Set parameters\n",
    "        self.nx = nx\n",
    "        self.nz = nz\n",
    "        self.dx = dx\n",
    "        self.dz = dz\n",
    "        self.dt = dt\n",
    "        self.params.update(kwargs)\n",
    "        dtype = getattr(self, 'dtype', np.float32)\n",
    "\n",
    "        # Define arrays\n",
    "        self.coords['x'] = np.arange(self.nx) * self.dx - self.nx * self.dx / 2\n",
    "        self.coords['x_stag'] = np.arange(self.nx + 1) * self.dx - (self.nx + 1) * self.dx / 2\n",
    "        self.coords['z'] = np.arange(self.nz) * self.dz\n",
    "        self.coords['z_stag'] = np.arange(self.nz + 1) * self.dz - self.dz / 2\n",
    "        self.prognostic_arrays['u'] = np.zeros((3, nz, nx + 1), dtype=dtype)\n",
    "        self.prognostic_arrays['w'] = np.zeros((3, nz + 1, nx), dtype=dtype)\n",
    "        self.prognostic_arrays['theta_p'] = np.zeros((3, nz, nx), dtype=dtype)\n",
    "        self.prognostic_arrays['pi'] = np.zeros((3, nz, nx), dtype=dtype)\n",
    "        self.active_prognostic_variables = ['u', 'w', 'theta_p', 'pi']\n",
    "        self.base_state_arrays['theta_base'] = np.zeros(nz, dtype=dtype)\n",
    "        self.base_state_arrays['PI_base'] = np.zeros(nz, dtype=dtype)\n",
    "        self.base_state_arrays['rho_base'] = np.zeros(nz, dtype=dtype)\n",
    "        ## Todo do we need others??\n",
    "\n",
    "    def initialize_isentropic_base_state(self, theta, pressure_surface):\n",
    "        # Set uniform potential temperature\n",
    "        self.base_state_arrays['theta_base'] = np.full(\n",
    "            self.base_state_arrays['theta_base'].shape, theta, dtype=self.dtype\n",
    "        )\n",
    "        # Calculate pi based on hydrostatic balance (from surface)\n",
    "        self.base_state_arrays['PI_base'] = nondimensional_pressure_hydrostatic(\n",
    "            self.base_state_arrays['theta_base'],\n",
    "            self.coords['z'],\n",
    "            pressure_surface\n",
    "        )\n",
    "        # Calculate density from theta and pi\n",
    "        self.base_state_arrays['rho_base'] = density_from_ideal_gas_law(\n",
    "            self.base_state_arrays['theta_base'],\n",
    "            self.base_state_arrays['PI_base']\n",
    "        )\n",
    "\n",
    "    def initialize_warm_bubble(self, amplitude, x_radius, z_radius, z_center):\n",
    "        if np.min(self.base_state_arrays['theta_base']) <= 0.:\n",
    "            raise ValueError(\"Base state theta must be initialized as positive definite\")\n",
    "\n",
    "        # Create thermal bubble (2D)\n",
    "        theta_p, pi = create_thermal_bubble(\n",
    "            amplitude, self.coords['x'], self.coords['z'], x_radius, z_radius, 0.0, z_center, \n",
    "            self.base_state_arrays['theta_base']\n",
    "        )\n",
    "        # Ensure boundary conditions, and add time stacking (future, current, past)\n",
    "        self.prognostic_arrays['theta_p'] = np.stack([apply_periodic_lateral_zerograd_vertical(theta_p)] * 3)\n",
    "        self.prognostic_arrays['pi'] = np.stack([apply_periodic_lateral_zerograd_vertical(pi)] * 3)\n",
    "        \n",
    "    def prep_new_timestep(self):\n",
    "        for var in self.active_prognostic_variables:\n",
    "            # Future-current to current-past\n",
    "            self.prognostic_arrays[var][0:2] = self.prognostic_arrays[var][1:3]\n",
    "\n",
    "    def take_first_timestep(self):\n",
    "        # check for needed parameters and methods\n",
    "        if not getattr(self, 'c_s_sqr'):\n",
    "            raise ValueError(\"Must set squared speed of sound prior to first timestep\")\n",
    "        if not (\n",
    "            getattr(self, 'u_tendency')\n",
    "            and getattr(self, 'w_tendency')\n",
    "            and getattr(self, 'theta_p_tendency')\n",
    "            and getattr(self, 'pi_tendency')\n",
    "        ):\n",
    "            \n",
    "        # Increment\n",
    "        self.t_count = 1\n",
    "\n",
    "        # Integrate forward-in-time\n",
    "        self.prognostic_arrays['u'][2] = (\n",
    "            self.prognostic_arrays['u'][1]\n",
    "            + self.dt * apply_periodic_lateral_zerograd_vertical(self.u_tendency(\n",
    "                self.prognostic_arrays['u'], self.prognostic_arrays['w'],\n",
    "                self.prognostic_arrays['pi'], self.base_state_arrays['theta_base'], self.dx, self.dz\n",
    "            ))\n",
    "        )\n",
    "        self.prognostic_arrays['w'][2] = (\n",
    "            self.prognostic_arrays['w'][1]\n",
    "            + self.dt * apply_periodic_lateral_zerograd_vertical(self.w_tendency(\n",
    "                self.prognostic_arrays['u'], self.prognostic_arrays['w'],\n",
    "                self.prognostic_arrays['pi'], self.prognostic_arrays['theta_p'],\n",
    "                self.base_state_arrays['theta_base'], self.dx, self.dz\n",
    "            ))\n",
    "        )\n",
    "        self.prognostic_arrays['theta_p'][2] = (\n",
    "            self.prognostic_arrays['theta_p'][1]\n",
    "            + self.dt * apply_periodic_lateral_zerograd_vertical(self.theta_p_tendency(\n",
    "                self.prognostic_arrays['u'], self.prognostic_arrays['w'],\n",
    "                self.prognostic_arrays['theta_p'], self.base_state_arrays['theta_base'], self.dx, self.dz\n",
    "            ))\n",
    "        )\n",
    "        self.prognostic_arrays['pi'][2] = (\n",
    "            self.prognostic_arrays['pi'][1]\n",
    "            + self.dt * apply_periodic_lateral_zerograd_vertical(self.pi_tendency(\n",
    "                self.prognostic_arrays['u'], self.prognostic_arrays['w'],\n",
    "                self.prognostic_arrays['pi'], self.base_state_arrays['theta_base'], \n",
    "                self.base_state_arrays['rho_base'], self.c_s_sqr, self.dx, self.dz\n",
    "            ))\n",
    "        )\n",
    "\n",
    "        self.prep_new_timestep()\n",
    "\n",
    "    def take_single_timestep(self):\n",
    "        # Check if initialized\n",
    "        if self.t_count == 0:\n",
    "            raise RuntimeError(\"Must run initial timestep!\")\n",
    "        self.t_count += 1\n",
    "\n",
    "        # Integrate leapfrog\n",
    "        self.prognostic_arrays['u'][2] = (\n",
    "            self.prognostic_arrays['u'][0]\n",
    "            + 2 * self.dt * apply_periodic_lateral_zerograd_vertical(self.u_tendency(\n",
    "                self.prognostic_arrays['u'], self.prognostic_arrays['w'],\n",
    "                self.prognostic_arrays['pi'], self.base_state_arrays['theta_base'], self.dx, self.dz\n",
    "            ))\n",
    "        )\n",
    "        self.prognostic_arrays['w'][2] = (\n",
    "            self.prognostic_arrays['w'][0]\n",
    "            + 2 * self.dt * apply_periodic_lateral_zerograd_vertical(self.w_tendency(\n",
    "                self.prognostic_arrays['u'], self.prognostic_arrays['w'],\n",
    "                self.prognostic_arrays['pi'], self.prognostic_arrays['theta_p'],\n",
    "                self.base_state_arrays['theta_base'], self.dx, self.dz\n",
    "            ))\n",
    "        )\n",
    "        self.prognostic_arrays['theta_p'][2] = (\n",
    "            self.prognostic_arrays['theta_p'][0]\n",
    "            + 2 * self.dt * apply_periodic_lateral_zerograd_vertical(self.theta_p_tendency(\n",
    "                self.prognostic_arrays['u'], self.prognostic_arrays['w'],\n",
    "                self.prognostic_arrays['theta_p'], self.base_state_arrays['theta_base'], self.dx, self.dz\n",
    "            ))\n",
    "        )\n",
    "        self.prognostic_arrays['pi'][2] = (\n",
    "            self.prognostic_arrays['pi'][0]\n",
    "            + 2 * self.dt * apply_periodic_lateral_zerograd_vertical(self.pi_tendency(\n",
    "                self.prognostic_arrays['u'], self.prognostic_arrays['w'],\n",
    "                self.prognostic_arrays['pi'], self.base_state_arrays['theta_base'], \n",
    "                self.base_state_arrays['rho_base'], self.c_s_sqr, self.dx, self.dz\n",
    "            ))\n",
    "        )\n",
    "\n",
    "        self.prep_new_timestep()\n",
    "\n",
    "    def current_state(self):\n",
    "        \"\"\"Export the prognostic variables, with coordinates, at current time.\"\"\"\n",
    "        data_vars = {}\n",
    "        for var in self.active_prognostic_variables:\n",
    "            if var == 'u':\n",
    "                dims = ('t', 'z', 'x_stag')\n",
    "            elif var == 'w':\n",
    "                dims = ('t', 'z_stag', 'x')\n",
    "            else:\n",
    "                dims = ('t', 'z', 'x')\n",
    "            data_vars[var] = xr.Variable(dims, self.arrays_prognostic[var][1:2].copy(), metadata_attrs[var])\n",
    "        data_vars['x'] = xr.Variable('x', self.x, metadata_attrs['x'])\n",
    "        data_vars['x_stag'] = xr.Variable('x_stag', self.x_stag, metadata_attrs['x_stag'])\n",
    "        data_vars['z'] = xr.Variable('z', self.z, metadata_attrs['z'])\n",
    "        data_vars['z_stag'] = xr.Variable('z_stag', self.z_stag, metadata_attrs['z_stag'])\n",
    "        data_vars['t'] = xr.Variable('t', [self.t_count * self.dt], metadata_attrs['t'])\n",
    "        return xr.Dataset(data_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "...TODO...\n",
    "\n",
    "Add one final `---` marking the end of your body of content, and then conclude with a brief single paragraph summarizing at a high level the key pieces that were learned and how they tied to your objectives. Look to reiterate what the most important takeaways were.\n",
    "\n",
    "### What's next?\n",
    "Let Jupyter book tie this to the next (sequential) piece of content that people could move on to down below and in the sidebar. However, if this page uniquely enables your reader to tackle other nonsequential concepts throughout this book, or even external content, link to it here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources and references\n",
    "Finally, be rigorous in your citations and references as necessary. Give credit where credit is due. Also, feel free to link to relevant external material, further reading, documentation, etc. Then you're done! Give yourself a quick review, a high five, and send us a pull request. A few final notes:\n",
    " - `Kernel > Restart Kernel and Run All Cells...` to confirm that your notebook will cleanly run from start to finish\n",
    " - `Kernel > Restart Kernel and Clear All Outputs...` before committing your notebook, our machines will do the heavy lifting\n",
    " - Take credit! Provide author contact information if you'd like; if so, consider adding information here at the bottom of your notebook\n",
    " - Give credit! Attribute appropriate authorship for referenced code, information, images, etc.\n",
    " - Only include what you're legally allowed: **no copyright infringement or plagiarism**\n",
    " \n",
    "Thank you for your contribution!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "Python 3"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    }
   ],
   "remote_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "Python3"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    }
   ]
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
